abstract: 'We present the Open Graph Benchmark (OGB), a diverse set of challenging
  and

  realistic benchmark datasets to facilitate scalable, robust, and reproducible

  graph machine learning (ML) research. OGB datasets are large-scale, encompass

  multiple important graph ML tasks, and cover a diverse range of domains,

  ranging from social and information networks to biological networks, molecular

  graphs, source code ASTs, and knowledge graphs. For each dataset, we provide a

  unified evaluation protocol using meaningful application-specific data splits

  and evaluation metrics. In addition to building the datasets, we also perform

  extensive benchmark experiments for each dataset. Our experiments suggest that

  OGB datasets present significant challenges of scalability to large-scale

  graphs and out-of-distribution generalization under realistic data splits,

  indicating fruitful opportunities for future research. Finally, OGB provides an

  automated end-to-end graph ML pipeline that simplifies and standardizes the

  process of graph data loading, experimental setup, and model evaluation. OGB

  will be regularly updated and welcomes inputs from the community. OGB datasets

  as well as data loaders, evaluation scripts, baseline code, and leaderboards

  are publicly available at https://ogb.stanford.edu .'
archiveprefix: arXiv
author: Weihua Hu and Matthias Fey and Marinka Zitnik and Yuxiao Dong and Hongyu Ren
  and Bowen Liu and Michele Catasta and Jure Leskovec
eprint: 2005.00687v5
file: 2005.00687v5.pdf
files:
- /Users/Roy/Documents/papers/2020-open-graph-benchmark-datasets-for-machine-learning-on-graphs.pdf
month: May
primaryclass: cs.LG
ref: 2005.00687v5
title: 'Open Graph Benchmark: Datasets for Machine Learning on Graphs'
type: article
url: http://arxiv.org/abs/2005.00687v5
year: '2020'
