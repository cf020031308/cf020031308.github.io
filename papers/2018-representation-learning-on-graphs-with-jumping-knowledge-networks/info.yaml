abstract: 'Recent deep learning approaches for representation learning on graphs follow

  a neighborhood aggregation procedure. We analyze some important properties of

  these models, and propose a strategy to overcome those. In particular, the

  range of "neighboring" nodes that a node''s representation draws from strongly

  depends on the graph structure, analogous to the spread of a random walk. To

  adapt to local neighborhood properties and tasks, we explore an architecture --

  jumping knowledge (JK) networks -- that flexibly leverages, for each node,

  different neighborhood ranges to enable better structure-aware representation.

  In a number of experiments on social, bioinformatics and citation networks, we

  demonstrate that our model achieves state-of-the-art performance. Furthermore,

  combining the JK framework with models like Graph Convolutional Networks,

  GraphSAGE and Graph Attention Networks consistently improves those models''

  performance.'
archiveprefix: arXiv
author: Keyulu Xu and Chengtao Li and Yonglong Tian and Tomohiro Sonobe and Ken-ichi
  Kawarabayashi and Stefanie Jegelka
eprint: 1806.03536v2
file: 1806.03536v2.pdf
files:
- /Users/Roy/Documents/papers/2018-representation-learning-on-graphs-with-jumping-knowledge-networks.pdf
month: Jun
primaryclass: cs.LG
ref: 1806.03536v2
title: Representation Learning on Graphs with Jumping Knowledge Networks
type: article
url: http://arxiv.org/abs/1806.03536v2
year: '2018'
