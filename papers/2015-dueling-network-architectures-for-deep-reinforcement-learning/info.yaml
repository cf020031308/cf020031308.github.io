abstract: 'In recent years there have been many successes of using deep representations

  in reinforcement learning. Still, many of these applications use conventional

  architectures, such as convolutional networks, LSTMs, or auto-encoders. In this

  paper, we present a new neural network architecture for model-free

  reinforcement learning. Our dueling network represents two separate estimators:

  one for the state value function and one for the state-dependent action

  advantage function. The main benefit of this factoring is to generalize

  learning across actions without imposing any change to the underlying

  reinforcement learning algorithm. Our results show that this architecture leads

  to better policy evaluation in the presence of many similar-valued actions.

  Moreover, the dueling architecture enables our RL agent to outperform the

  state-of-the-art on the Atari 2600 domain.'
archiveprefix: arXiv
author: Ziyu Wang and Tom Schaul and Matteo Hessel and Hado van Hasselt and Marc Lanctot
  and Nando de Freitas
eprint: 1511.06581v3
file: 1511.06581v3.pdf
files:
- /Users/Roy/Documents/papers/2015-dueling-network-architectures-for-deep-reinforcement-learning.pdf
month: Nov
primaryclass: cs.LG
ref: 1511.06581v3
title: Dueling Network Architectures for Deep Reinforcement Learning
type: article
url: http://arxiv.org/abs/1511.06581v3
year: '2015'
